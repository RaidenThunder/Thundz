{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276aedc7",
   "metadata": {},
   "source": [
    "# Cat vs Dog Classification using Deep Neural Networks\n",
    "\n",
    "This notebook explores multiple deep learning models to classify images of cats and dogs using the `cats_vs_dogs` dataset from TensorFlow Datasets. It compares different DNN architectures to evaluate their performance and identify the most effective model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the required libraries\n",
    "# =================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e077cb",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Load the dataset\n",
    "# --------------------\n",
    "(train_ds, val_ds, test_ds), info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74618a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Visualize the data\n",
    "# ----------------------\n",
    "print(\"--- Sample Images from the Training Dataset ---\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (image, label) in enumerate(train_ds.take(10)):\n",
    "    ax = plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Cat' if label == 0 else 'Dog')\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Pre-process the data\n",
    "# ------------------------\n",
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def preprocess(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "  return image, label\n",
    "\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)\n",
    "test_ds = test_ds.map(preprocess)\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"\\nData pre-processing complete. Images resized to {IMG_SIZE}x{IMG_SIZE} and batched.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7bb9b",
   "metadata": {},
   "source": [
    "## 3. Code for the Deep Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Basic CNN\n",
    "model1 = Sequential([\n",
    "    Flatten(input_shape=(150, 150, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name=\"Basic_CNN\")\n",
    "\n",
    "# Model 2: Deeper CNN\n",
    "model2 = Sequential([\n",
    "    Flatten(input_shape=(150, 150, 3)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name=\"Deeper_CNN\")\n",
    "\n",
    "# Model 3: CNN with Dropout\n",
    "model3 = Sequential([\n",
    "    Flatten(input_shape=(150, 150, 3)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name=\"CNN_with_Dropout\")\n",
    "\n",
    "# Model 4: CNN with Batch Normalization\n",
    "model4 = Sequential([\n",
    "    Flatten(input_shape=(150, 150, 3)),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name=\"CNN_with_Batch_Norm\")\n",
    "\n",
    "# Model 5: CNN with L2 Regularization\n",
    "model5 = Sequential([\n",
    "    Flatten(input_shape=(150, 150, 3)),\n",
    "    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name=\"CNN_with_L2_Regularization\")\n",
    "\n",
    "models = [model1, model2, model3, model4, model5]\n",
    "for model in models:\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(f\"--- {model.name} Summary ---\")\n",
    "    model.summary()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ccc0e2",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "epochs = 10\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n--- Training {model.name} ---\")\n",
    "    history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=2)\n",
    "    histories.append({'name': model.name, 'history': history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aaeb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(histories, metric, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for item in histories:\n",
    "        name = item['name']\n",
    "        history = item['history']\n",
    "        val_metric = f'val_{metric}'\n",
    "        plt.plot(history.history[metric], label=f'{name} Train {metric.capitalize()}', lw=2)\n",
    "        plt.plot(history.history[val_metric], label=f'{name} Val {metric.capitalize()}', linestyle='--')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel(metric.capitalize(), fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "plot_metric(histories, 'accuracy', 'Model Comparison: Accuracy')\n",
    "plot_metric(histories, 'loss', 'Model Comparison: Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fdac5a",
   "metadata": {},
   "source": [
    "## 5. Test the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36461759",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model4\n",
    "\n",
    "print(f\"\\n--- Evaluating Best Model ({best_model.name}) on Test Data ---\")\n",
    "loss, accuracy = best_model.evaluate(test_ds)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "y_pred_probs = best_model.predict(test_ds)\n",
    "y_pred = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Cat', 'Dog']))\n",
    "\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Cat', 'Dog'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(f'Confusion Matrix for {best_model.name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0db9a",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This notebook demonstrated building, training, and evaluating several deep learning models for image classification.\n",
    "By comparing different architectures, we selected the one that performs best on our specific task.\n",
    "Model 4, with Batch Normalization, appears to be a good choice due to its stable training and high accuracy.\n",
    "Further improvements could be made by tuning hyperparameters, using more advanced architectures (e.g., adding Convolutional layers),\n",
    "or employing data augmentation techniques.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}